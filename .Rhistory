knitr::opts_chunk$set(echo = TRUE)
bc<-read.table("https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data",header=F,sep=",")
names(bc)<- c('id_number', 'diagnosis', 'radius_mean',
'texture_mean', 'perimeter_mean', 'area_mean',
'smoothness_mean', 'compactness_mean',
'concavity_mean','concave_points_mean',
'symmetry_mean', 'fractal_dimension_mean',
'radius_se', 'texture_se', 'perimeter_se',
'area_se', 'smoothness_se', 'compactness_se',
'concavity_se', 'concave_points_se',
'symmetry_se', 'fractal_dimension_se',
'radius_worst', 'texture_worst',
'perimeter_worst', 'area_worst',
'smoothness_worst', 'compactness_worst',
'concavity_worst', 'concave_points_worst',
'symmetry_worst', 'fractal_dimension_worst')
#Getting a look at the distribution of the response
table(bc$diagnosis)
#Train/Validation Split
library(caret)
set.seed(1234)
trainIndex<-createDataPartition(bc$diagnosis,p=.5,list=F)  #p: proportion of data in train
training<-bc[trainIndex,]
validate<-bc[-trainIndex,]
library(glmnet)
# Create a GLMNET model with alpha = 1 (Lasso) and lambda = 1
model <- glmnet(x = training, y = training$diagnosis, alpha = 1, lambda = 1)
View(training)
library(glmnet)
# Convert the response variable to a numeric variable
training$diagnosis <- as.numeric(training$diagnosis) - 1
# Create a GLMNET model with alpha = 1 (Lasso) and lambda = 1
model <- glmnet(x = training, y = training$diagnosis, alpha = 1, lambda = 1)
library(glmnet)
# Convert the response variable to a numeric variable
training$diagnosis <- as.numeric(training$diagnosis) - 1
# Impute the missing values
training <- missForest(training, maxiter = 5)$imputed
library(glmnet)
library(missForest)
# Convert the response variable to a numeric variable
training$diagnosis <- as.numeric(training$diagnosis) - 1
# Impute the missing values
training <- missForest(training, maxiter = 5)$imputed
# Create a GLMNET model with alpha = 1 (Lasso) and lambda = 1
model <- glmnet(x = training, y = training$diagnosis, alpha = 1, lambda = 1)
library(glmnet)
library(missForest)
# Convert the response variable to a numeric variable
training$diagnosis <- as.numeric(training$diagnosis) - 1
# Impute the missing values
training <- missForest(training, maxiter = 5)$imputed
View(training)
bc<-read.table("https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data",header=F,sep=",")
names(bc)<- c('id_number', 'diagnosis', 'radius_mean',
'texture_mean', 'perimeter_mean', 'area_mean',
'smoothness_mean', 'compactness_mean',
'concavity_mean','concave_points_mean',
'symmetry_mean', 'fractal_dimension_mean',
'radius_se', 'texture_se', 'perimeter_se',
'area_se', 'smoothness_se', 'compactness_se',
'concavity_se', 'concave_points_se',
'symmetry_se', 'fractal_dimension_se',
'radius_worst', 'texture_worst',
'perimeter_worst', 'area_worst',
'smoothness_worst', 'compactness_worst',
'concavity_worst', 'concave_points_worst',
'symmetry_worst', 'fractal_dimension_worst')
#Getting a look at the distribution of the response
table(bc$diagnosis)
#Train/Validation Split
library(caret)
set.seed(1234)
trainIndex<-createDataPartition(bc$diagnosis,p=.5,list=F)  #p: proportion of data in train
training<-bc[trainIndex,]
validate<-bc[-trainIndex,]
library(glmnet)
library(missForest)
# Convert the response variable to a numeric variable
training$diagnosis <- as.numeric(training$diagnosis) - 1
# Impute the missing values
training <- missForest(training, maxiter = 5)$imputed
# Create a GLMNET model with alpha = 1 (Lasso) and lambda = 1
model <- glmnet(x = training, y = training$diagnosis, alpha = 1, lambda = 1)
library(glmnet)
library(caret)
fit <- cv.glmnet(x = training[, -1], y = training$diagnosis, alpha = 1, nfolds = 10, type.measure = "logloss")
fit <- cv.glmnet(x = training[, -1], y = training$diagnosis, alpha = 1, nfolds = 10, type.measure = "default")
library(glmnet)
library(caret)
fitControl<-trainControl(method="repeatedcv",number=5,repeats=1,classProbs=TRUE, summaryFunction=mnLogLoss)
set.seed(1234)
#GLMNET
glmnet.fit<-train(diagnosis~.,
data=training,
method="glmnet",
trControl=fitControl,
metric="logLoss")
bc<-read.table("https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data",header=F,sep=",")
names(bc)<- c('id_number', 'diagnosis', 'radius_mean',
'texture_mean', 'perimeter_mean', 'area_mean',
'smoothness_mean', 'compactness_mean',
'concavity_mean','concave_points_mean',
'symmetry_mean', 'fractal_dimension_mean',
'radius_se', 'texture_se', 'perimeter_se',
'area_se', 'smoothness_se', 'compactness_se',
'concavity_se', 'concave_points_se',
'symmetry_se', 'fractal_dimension_se',
'radius_worst', 'texture_worst',
'perimeter_worst', 'area_worst',
'smoothness_worst', 'compactness_worst',
'concavity_worst', 'concave_points_worst',
'symmetry_worst', 'fractal_dimension_worst')
#Getting a look at the distribution of the response
table(bc$diagnosis)
#Train/Validation Split
library(caret)
set.seed(1234)
trainIndex<-createDataPartition(bc$diagnosis,p=.5,list=F)  #p: proportion of data in train
training<-bc[trainIndex,]
validate<-bc[-trainIndex,]
library(glmnet)
library(caret)
fitControl<-trainControl(method="repeatedcv",number=5,repeats=1,classProbs=TRUE, summaryFunction=mnLogLoss)
set.seed(1234)
#GLMNET
glmnet.fit<-train(diagnosis~ ,
library(glmnet)
library(caret)
fitControl<-trainControl(method="repeatedcv",number=5,repeats=1,classProbs=TRUE, summaryFunction=mnLogLoss)
set.seed(1234)
#GLMNET
glmnet.fit<-train(diagnosis~ . ,
data=training,
method="glmnet",
trControl=fitControl,
metric="logLoss")
coef(glmnet.fit$finalModel,glmnet.fit$finalModel$lambdaOpt)
library(glmnet)
library(caret)
fitControl<-trainControl(method="repeatedcv",number=10,repeats=1,classProbs=TRUE, summaryFunction=mnLogLoss)
set.seed(1234)
#GLMNET
glmnet.fit<-train(diagnosis~ . ,
data=training,
method="glmnet",
trControl=fitControl,
metric="logLoss")
coef(glmnet.fit$finalModel,glmnet.fit$finalModel$lambdaOpt)
# libraries
library(glmnet)
library(caret)
library(pROC)
# knn model
knn.fit <- train(diagnosis ~ ., data = training, method = "knn", trControl = fitControl, metric = "logLoss")
# evaluate
logloss <- logLoss(predict(knn.fit, validate[, -1], type = "prob")[, 1], validate$diagnosis)
# evaluate
logLoss <- logLoss(predict(knn.fit, validate[, -1], type = "prob")[, 2], validate$diagnosis)
auc <- auc(predict(knn.fit, validate[, -1], type = "prob")[, 2], validate$diagnosis)
# libraries
library(glmnet)
library(caret)
library(pROC)
# knn model
knn.fit <- train(diagnosis ~ ., data = training, method = "knn", trControl = fitControl, metric = "logLoss")
# evaluate
logLoss <- logLoss(predict(knn.fit, validate[, -1], type = "prob")[, 2], validate$diagnosis)
roc.glmnet <- roc(validate$diagnosis, predict(glmnet.fit, validate[, -1], type = "prob")[, 1])
# libraries
library(glmnet)
library(caret)
library(pROC)
# knn model
knn.fit <- train(diagnosis ~ ., data = training, method = "knn", trControl = fitControl, metric = "logLoss")
# evaluate
logLoss <- logLoss(predict(knn.fit, validate[, -1], type = "prob")[, 2], validate$diagnosis)
auc <- auc(predict(knn.fit, validate[, -1], type = "prob")[, 2], validate$diagnosis)
# libraries
library(glmnet)
library(caret)
library(pROC)
# knn model
knn.fit <- train(diagnosis ~ ., data = training, method = "knn", trControl = fitControl, metric = "logLoss")
# Obtain the predicted probabilities for the KNN model
knn.probs <- predict(knn.fit, newdata = validate, type = "prob")
# Compute ROC curve for KNN model
knn.roc <- roc(validate$diagnosis, knn.probs[, "1"])
# libraries
library(glmnet)
library(caret)
library(pROC)
# knn model
knn.fit <- train(diagnosis ~ ., data = training, method = "knn", trControl = fitControl, metric = "logLoss")
# Obtain the predicted probabilities for the KNN model
knn.probs <- as.numeric(predict(knn.fit, newdata = validate, type = "prob")[, 2])
# Compute ROC curve for KNN model
knn.roc <- roc(validate$diagnosis, knn.probs)
# Obtain the predicted probabilities for the GLMNET model
glmnet.probs <- predict(glmnet.fit, newdata = validate, type = "response")
# libraries
library(glmnet)
library(caret)
library(pROC)
# knn model
knn.fit <- train(diagnosis ~ ., data = training, method = "knn", trControl = fitControl, metric = "logLoss")
# Obtain the predicted probabilities for the KNN model
knn.probs <- as.numeric(predict(knn.fit, newdata = validate, type = "prob")[, 2])
# Compute ROC curve for KNN model
knn.roc <- roc(validate$diagnosis, knn.probs)
# Obtain the predicted probabilities for the GLMNET model
glmnet.probs <- predict(glmnet.fit, newx = as.matrix(predictMatrix), s = "lambda.min")
# Compute ROC curve for GLMNET model
glmnet.roc <- roc(validate$diagnosis, glmnet.probs)
# Load necessary packages
library(caret)
library(pROC)
# Train KNN model with 10-fold cross-validation
knn.fit <- train(diagnosis ~ .,
data = training,
method = "knn",
trControl = fitControl,
metric = "logLoss")
# Obtain the predicted probabilities for the KNN model
knn.probs <- as.numeric(predict(knn.fit, newdata = validate, type = "prob")[, 2])
# Convert the response variable to numeric for ROC curve calculation
validate$diagnosis_numeric <- ifelse(validate$diagnosis == "M", 1, 0)
# Compute ROC curve for KNN model
knn.roc <- roc(validate$diagnosis_numeric, knn.probs)
# Obtain the predicted probabilities for the GLMNET model
glmnet.probs <- predict(glmnet.fit, newx = as.matrix(predictMatrix), s = "lambda.min")
# Compute ROC curve for GLMNET model
glmnet.roc <- roc(validate$diagnosis_numeric, glmnet.probs)
# Load necessary packages
library(caret)
library(pROC)
# Train KNN model with 10-fold cross-validation
knn.fit <- train(diagnosis ~ .,
data = training,
method = "knn",
trControl = fitControl,
metric = "logLoss")
# Obtain the predicted probabilities for the KNN model
knn.probs <- as.numeric(predict(knn.fit, newdata = validate, type = "prob")[, 2])
# Convert the response variable to numeric for ROC curve calculation
validate$diagnosis_numeric <- ifelse(validate$diagnosis == "M", 1, 0)
# Convert the GLMNET predicted probabilities to numeric
glmnet.probs <- as.numeric(predict(glmnet.fit, newx = as.matrix(validate[, -2]), s = "lambda.min"))
# Compute ROC curve for KNN model
knn.roc <- roc(validate$diagnosis_numeric, knn.probs)
# Compute ROC curve for GLMNET model
glmnet.roc <- roc(validate$diagnosis_numeric, glmnet.probs)
plot(knn.roc, col = "red", add = TRUE, lty = 2)
# Plot ROC curves
plot(glmnet.roc, col = "blue", main = "ROC Curve Comparison", lty = 1, xlim = c(0, 1), ylim = c(0, 1))
plot(knn.roc, col = "red", add = TRUE, lty = 2)
legend(0.6, 0.2, legend = c("GLMNET", "KNN"), col = c("blue", "red"), lty = 1:2, cex = 0.8)
# Calculate AUROC values
glmnet.auroc <- auc(glmnet.roc)
knn.auroc <- auc(knn.roc)
print(paste("GLMNET AUROC:", glmnet.auroc))
